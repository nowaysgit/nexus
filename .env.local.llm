# Environment конфигурация для локального Llama 4 LLM
# Используется для development и локального тестирования

# LLM Configuration
LLM_ACTIVE_PROVIDER=llama
LLM_FALLBACK_ENABLED=true
LLM_RETRY_ATTEMPTS=3
LLM_TIMEOUT=60000
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL=3600

# Llama Provider Configuration
LLM_LLAMA_ENABLED=true
LLM_LLAMA_PRIORITY=1
LLM_LLAMA_ENDPOINT=http://localhost:11434
LLM_LLAMA_API_KEY=
LLM_LLAMA_MODEL=llama3.2:3b
LLM_LLAMA_TIMEOUT=60000

# Llama Light для тестов
LLM_LLAMA_LIGHT_ENDPOINT=http://localhost:11435
LLM_LLAMA_LIGHT_MODEL=llama3.2:1b

# OpenAI Fallback (опционально)
LLM_OPENAI_ENABLED=false
LLM_OPENAI_PRIORITY=2
LLM_OPENAI_API_KEY=your_openai_api_key_here

# Claude Fallback (опционально)
LLM_CLAUDE_ENABLED=false
LLM_CLAUDE_PRIORITY=3
LLM_CLAUDE_API_KEY=your_claude_api_key_here

# Redis для LLM кеширования
REDIS_LLM_HOST=localhost
REDIS_LLM_PORT=6381
REDIS_LLM_PASSWORD=
REDIS_LLM_DB=1

# Мониторинг LLM
LLM_MONITORING_ENABLED=true
LLM_METRICS_RESPONSE_TIME=true
LLM_METRICS_TOKEN_USAGE=true
LLM_METRICS_ERROR_RATE=true

# Логирование LLM запросов
LLM_LOGGING_ENABLED=true
LLM_LOGGING_LEVEL=info
LLM_LOG_REQUESTS=true
LLM_LOG_RESPONSES=false
